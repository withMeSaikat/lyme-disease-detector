{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries\n> `OpenCV` is not used.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom skimage.transform import rescale, resize, downscale_local_mean\n#import cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG19\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nimport warnings\nfrom datetime import datetime\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:45:57.271647Z","iopub.execute_input":"2021-12-29T11:45:57.271901Z","iopub.status.idle":"2021-12-29T11:45:57.278463Z","shell.execute_reply.started":"2021-12-29T11:45:57.271872Z","shell.execute_reply":"2021-12-29T11:45:57.277685Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"root = \"../input/lyme-disease-rashes/\"\nimg = io.imread(root + \"RashData/Lyme_Positive_By_Diease/EMRash/erythema migrans42.jpg\")\nplt.imshow(img)\nplt.title(\"Raw Image\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:46:03.203065Z","iopub.execute_input":"2021-12-29T11:46:03.203817Z","iopub.status.idle":"2021-12-29T11:46:03.508287Z","shell.execute_reply.started":"2021-12-29T11:46:03.203777Z","shell.execute_reply":"2021-12-29T11:46:03.507493Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"HEIGHT, WIDTH = 300, 300\nresized_img = resize(img, (HEIGHT, WIDTH))\nplt.imshow(resized_img)\nplt.title(\"Resized Image\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:46:05.311740Z","iopub.execute_input":"2021-12-29T11:46:05.312021Z","iopub.status.idle":"2021-12-29T11:46:05.615383Z","shell.execute_reply.started":"2021-12-29T11:46:05.311989Z","shell.execute_reply":"2021-12-29T11:46:05.614735Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Importing the data\n1. Loading the data from root directory\n2. Each image is resized into `200 * 200` dimension\n3. The imported image is converted into an numpy array\n4. Each data is normalized","metadata":{}},{"cell_type":"code","source":"# Creating the dataset for processing -- Using SKIMAGE\npath_root = root + \"RashData/Train/Train_2_Cases\"\ndata = []\ncategories = [\"Negative\", \"Positive\"]\nflag = True\nfor category in categories:\n    path = os.path.join(path_root, \"Lyme_\" + category)\n    label = categories.index(category)\n    \n    for img in os.listdir(path):\n        try:\n            img_path = os.path.join(path, img)\n            dis_img = io.imread(img_path)\n            if flag:\n                print(type(dis_img))\n                flag = False\n    \n            image = resize(dis_img, (HEIGHT, WIDTH))\n#             image = np.array(dis_img).flatten()\n            data.append([image, label])\n        except Exception as e:\n            print(\"Could not add image.\")","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-29T11:46:07.681637Z","iopub.execute_input":"2021-12-29T11:46:07.682270Z","iopub.status.idle":"2021-12-29T11:46:36.476493Z","shell.execute_reply.started":"2021-12-29T11:46:07.682230Z","shell.execute_reply":"2021-12-29T11:46:36.475539Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Spliting the data array into -\n* Image Feature Vector(image_ds)\n* Corresponding Labels(labels)","metadata":{}},{"cell_type":"code","source":"\nimage_ds = np.array([obj[0][:,:,0] for obj in data])\nlabels = np.array([obj[1] for obj in data])\nprint(image_ds.shape)\n#image_ds = image_ds.reshape((356, 200, 200, 1))\nlen(labels[labels == 1])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:49:46.181865Z","iopub.execute_input":"2021-12-29T11:49:46.182606Z","iopub.status.idle":"2021-12-29T11:49:46.308442Z","shell.execute_reply.started":"2021-12-29T11:49:46.182566Z","shell.execute_reply":"2021-12-29T11:49:46.307676Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Creating Train and Test Data\n> Using 20 percent of data as the test data.","metadata":{}},{"cell_type":"code","source":"train_x, test_x, train_y, test_y = train_test_split(image_ds, labels, test_size=0.20, shuffle=True)\nprint(\"Size of training data:\", train_x.shape)\nprint(\"Size of test data:\", test_x.shape)\nlen(train_y[train_y==1])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:49:49.721711Z","iopub.execute_input":"2021-12-29T11:49:49.721988Z","iopub.status.idle":"2021-12-29T11:49:49.808666Z","shell.execute_reply.started":"2021-12-29T11:49:49.721955Z","shell.execute_reply":"2021-12-29T11:49:49.807913Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Using Support Vector Machine for Trainning:\n1. The training and testing data is flattened\n2. Model is defined with a `Polynomial` kernel\n3. Model is trained \n4. Confusion Matrix and Classification Report is observed","metadata":{}},{"cell_type":"code","source":"train_x_flat = train_x.reshape((train_x.shape[0], HEIGHT * WIDTH))\ntest_x_flat = test_x.reshape((test_x.shape[0], HEIGHT * WIDTH))\nprint(train_x_flat.shape)\nmodel_svm = SVC(kernel='poly', gamma='auto')\nmodel_svm.fit(train_x_flat, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:49:54.881665Z","iopub.execute_input":"2021-12-29T11:49:54.882217Z","iopub.status.idle":"2021-12-29T11:50:04.691676Z","shell.execute_reply.started":"2021-12-29T11:49:54.882177Z","shell.execute_reply":"2021-12-29T11:50:04.690969Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pred_y = model_svm.predict(test_x_flat)\nprint(confusion_matrix(test_y, pred_y))\nprint(classification_report(test_y, pred_y))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:50:11.082284Z","iopub.execute_input":"2021-12-29T11:50:11.082738Z","iopub.status.idle":"2021-12-29T11:50:13.452191Z","shell.execute_reply.started":"2021-12-29T11:50:11.082701Z","shell.execute_reply":"2021-12-29T11:50:13.451501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Using Deep Feed Forward Network to train\n+ Using a fully connected network to train \n+ The network consists of two hidden layer of size `20000 * 1`\n+ Finally using a output layer with `sigmoid` activation as it is binary classification\n> Assuming the input images are of dimension `100 * 100`.","metadata":{}},{"cell_type":"code","source":"model_dense = keras.models.Sequential([\n    keras.Input(shape=(100 * 100,)),\n    keras.layers.Dense(2 * 100 * 100, activation='relu'),\n    keras.layers.Dense(2 * 100 * 100, activation='relu'),\n    keras.layers.Dense(1)\n])\nmodel_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_dense.fit(train_x_flat, train_y, batch_size=32, epochs=20,steps_per_epoch=4)","metadata":{"execution":{"iopub.execute_input":"2021-12-27T16:09:53.300346Z","iopub.status.busy":"2021-12-27T16:09:53.300002Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = model_dense.evaluate(test_x_flat, test_y)\nprint(report)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using CNN to train\nThis is executed in following steps:\n1. First we rescale the training and validation data in range `[0, 1]`\n2. Then we define 5 convolution layers with MaxPool layers and `relu` activation\n3. Last output layer is of size 1 and using `sigmoid` activation function","metadata":{}},{"cell_type":"code","source":"train = ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\nvalidation = ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n\ntrain_ds = train.flow_from_directory(root + \"RashData/Train/Train_2_Cases\", target_size=(HEIGHT, WIDTH),\n                                    batch_size=10, class_mode='binary')\nval_ds = validation.flow_from_directory(root + \"RashData/Validation/Validation_2_Cases\", target_size=(HEIGHT, WIDTH),\n                                       batch_size=10, class_mode='binary')\nval_ds.class_indices\nfilter_size = (2, 2)\nepochs = 25","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:50:25.392698Z","iopub.execute_input":"2021-12-29T11:50:25.392975Z","iopub.status.idle":"2021-12-29T11:50:25.617498Z","shell.execute_reply.started":"2021-12-29T11:50:25.392940Z","shell.execute_reply":"2021-12-29T11:50:25.616779Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_conv_2d = keras.models.Sequential([\n    keras.layers.Conv2D(32, filter_size, activation='relu', input_shape=(HEIGHT, WIDTH, 3), kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(2, 2),\n    keras.layers.Conv2D(64, filter_size, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(2, 2),\n    keras.layers.Conv2D(128, filter_size, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(2, 2),\n    keras.layers.Conv2D(256, filter_size, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(2, 2),\n    keras.layers.Conv2D(512, filter_size, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(2, 2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n    keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T10:35:20.051221Z","iopub.execute_input":"2021-12-29T10:35:20.051486Z","iopub.status.idle":"2021-12-29T10:35:22.415305Z","shell.execute_reply.started":"2021-12-29T10:35:20.051456Z","shell.execute_reply":"2021-12-29T10:35:22.413476Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_conv_2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory_conv_2d = model_conv_2d.fit(train_ds, steps_per_epoch=3, epochs=epochs, validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T10:35:33.817507Z","iopub.execute_input":"2021-12-29T10:35:33.818206Z","iopub.status.idle":"2021-12-29T10:37:32.277777Z","shell.execute_reply.started":"2021-12-29T10:35:33.818157Z","shell.execute_reply":"2021-12-29T10:37:32.276871Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\n\nepochs_range = range(1, epochs + 1)\ntrain_loss = history_conv_2d.history['loss']\nval_loss = history_conv_2d.history['val_loss']\n# train_auc = history.history['auc']\n# val_auc = history.history['val_auc']\n\n# plt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\n\n# plt.subplot(1, 2, 2)\n# plt.plot(epochs_range, train_auc, label=\"Training AUC\", color='b')\n# plt.plot(epochs_range, val_auc, label=\"Validation AUC\", color='r')\n\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"AUC\")\n# plt.title(\"Training and Validation AUC\")\n# plt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T10:37:39.051455Z","iopub.execute_input":"2021-12-29T10:37:39.051723Z","iopub.status.idle":"2021-12-29T10:37:39.316221Z","shell.execute_reply.started":"2021-12-29T10:37:39.051693Z","shell.execute_reply":"2021-12-29T10:37:39.315445Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Using different state of the art models\n+ VGG19\n+ ResNet","metadata":{}},{"cell_type":"code","source":"DIMS_VGG = (224, 224, 3)\ntrain_vgg = train.flow_from_directory(root + \"RashData/Train/Train_2_Cases\", target_size=(DIMS_VGG[0], DIMS_VGG[1]),\n                                    batch_size=10, class_mode='binary')\nval_vgg = validation.flow_from_directory(root + \"RashData/Validation/Validation_2_Cases\", \n                                         target_size=(DIMS_VGG[0], DIMS_VGG[1]), batch_size=10, class_mode='binary')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:52:51.961822Z","iopub.execute_input":"2021-12-29T11:52:51.962784Z","iopub.status.idle":"2021-12-29T11:52:52.182263Z","shell.execute_reply.started":"2021-12-29T11:52:51.962736Z","shell.execute_reply":"2021-12-29T11:52:52.181508Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nSTEP_SIZE_TRAIN = train_vgg.n // train_vgg.batch_size\nSTEP_SIZE_VAL = val_vgg.n // val_vgg.batch_size\nEPOCH_VGG = 15","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:52:54.611863Z","iopub.execute_input":"2021-12-29T11:52:54.612472Z","iopub.status.idle":"2021-12-29T11:52:54.616707Z","shell.execute_reply.started":"2021-12-29T11:52:54.612403Z","shell.execute_reply":"2021-12-29T11:52:54.615999Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vgg = VGG19(input_shape=DIMS_VGG, weights='imagenet', include_top=False)\n\nfor layer in vgg.layers:\n    layer.trainable = False\n\nx = keras.layers.Flatten()(vgg.output)\nhidd1 = keras.layers.Dense(1024, activation='relu')(x)\npred = keras.layers.Dense(1, activation='sigmoid')(hidd1)\n\nmodel_vgg = keras.Model(inputs=vgg.input, outputs=pred)\n\nmodel_vgg.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_vgg.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:53:33.381503Z","iopub.execute_input":"2021-12-29T11:53:33.381772Z","iopub.status.idle":"2021-12-29T11:53:37.206443Z","shell.execute_reply.started":"2021-12-29T11:53:33.381743Z","shell.execute_reply":"2021-12-29T11:53:37.205736Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5,\n                               min_lr=0.5e-6)\ncheckpoint = ModelCheckpoint(filepath='./Models/model_vgg.h5', verbose=1, save_best_only=True)\n\ncallbacks = [checkpoint, lr_reducer]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:55:54.623545Z","iopub.execute_input":"2021-12-29T11:55:54.623811Z","iopub.status.idle":"2021-12-29T11:55:54.629119Z","shell.execute_reply.started":"2021-12-29T11:55:54.623783Z","shell.execute_reply":"2021-12-29T11:55:54.628332Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"start = datetime.now()\nhistory_vgg = model_vgg.fit_generator(train_vgg, \n                    steps_per_epoch=STEP_SIZE_TRAIN, \n                    epochs = EPOCH_VGG, verbose=5, \n                    validation_data = val_vgg, \n                    validation_steps = STEP_SIZE_VAL,\n                    callbacks=[checkpoint])\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:03.908476Z","iopub.execute_input":"2021-12-29T11:56:03.908751Z","iopub.status.idle":"2021-12-29T11:58:36.798555Z","shell.execute_reply.started":"2021-12-29T11:56:03.908721Z","shell.execute_reply":"2021-12-29T11:58:36.797661Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"score_val = model_vgg.evaluate(val_vgg)\nscore_train = model_vgg.evaluate(train_vgg)\nprint('Test Loss:', score_val[0])\nprint('Test accuracy:', score_val[1])\nprint('Train Loss:', score_train[0])\nprint('Train accuracy:', score_train[1])\nplt.plot(history_vgg.history['accuracy'])\nplt.plot(history_vgg.history['val_accuracy'])\nplt.plot(history_vgg.history['loss'])\nplt.plot(history_vgg.history['val_loss'])\nplt.title('model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy','Validation Accuracy','loss','Validation Loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:58:59.083688Z","iopub.execute_input":"2021-12-29T11:58:59.083977Z","iopub.status.idle":"2021-12-29T11:59:07.164097Z","shell.execute_reply.started":"2021-12-29T11:58:59.083940Z","shell.execute_reply":"2021-12-29T11:59:07.163419Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}